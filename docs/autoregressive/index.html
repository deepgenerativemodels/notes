<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Autoregressive Models</title>
  <meta name="description" content="Lecture notes for Deep Generative Models.">


  <link rel="stylesheet" href="/notes/css/tufte.css">	
  

  <!-- Google Fonts loaded here depending on setting in _data/options.yml true loads font, blank does not-->
  
    <link href='//fonts.googleapis.com/css?family=Lato:400,400italic' rel='stylesheet' type='text/css'>
  
  <!-- Load up MathJax script if needed ... specify in /_data/options.yml file-->
  
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  

  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-129020129-1', 'auto');
  ga('send', 'pageview');

  </script>

  <link rel="canonical" href="http://localhost:4000/notes/autoregressive/">
  <link rel="alternate" type="application/rss+xml" title="Deep Generative Models" href="http://localhost:4000/notes/feed.xml" />
</head>

  <body>
    <!--- Header and nav template site-wide -->
<header>
    <nav class="group">
        <a href="/notes/">Contents</a>
	<a href="http://deepgenerativemodels.github.io">Class</a>
	<a href="http://github.com/deepgenerativemodels/notes">Github</a>
	</nav>
</header>

    <article class="group">
      <h1>Autoregressive models</h1>
<p class="subtitle"></p>


<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        e: "\\epsilon",
        xti: "x^{(i)}",
        yti: "y^{(i)}",
        bfy: "{\\bf y}",
        bfx: "{\\bf x}",
        bfg: "{\\bf g}",
        bfbeta: "{\\bf \\beta}",
        tp: "\\tilde p",
        pt: "p_\\theta",
        Exp: "{\\mathbb{E}}",
        Ind: "{\\mathbb{I}}",
        KL: "{\\mathbb{KL}}",
        Dc: "{\\mathcal{D}}",
        Tc: "{\\mathcal{T}}",
        Xc: "{\\mathcal{X}}",
        note: ["\\textcolor{blue}{[NOTE: #1]}",1]
      }
    }
  });
</script>


<p>We begin our study into generative modeling with autoregressive models. As before, we assume we are given access to a dataset <script type="math/tex">\mathcal{D}</script> of <script type="math/tex">n</script>-dimensional datapoints <script type="math/tex">\mathbf{x}</script>. For simplicity, we assume the datapoints are binary, i.e., <script type="math/tex">\mathbf{x} \in \{0,1\}^n</script>.</p>

<h1 id="representation">Representation</h1>

<p>By the chain rule of probability, we can factorize the joint distribution over the <script type="math/tex">n</script>-dimensions as</p>

<div class="mathblock"><script type="math/tex; mode=display">
p(\mathbf{x}) = \prod\limits_{i=1}^{n}p(x_i \vert x_1, x_2, \ldots, x_{i-1}) = 
\prod\limits_{i=1}^{n} p(x_i \vert \mathbf{x}_{< i } )
</script></div>

<p>where <script type="math/tex">% <![CDATA[
\mathbf{x}_{< i}=[x_1, x_2, \ldots, x_{i-1}] %]]></script> denotes the vector of random variables with index less than <script type="math/tex">i</script>.</p>

<p>The chain rule factorization can be expressed graphically as a Bayesian network.</p>

<figure>
<img src="autoregressive.png" alt="drawing" width="400" class="center" />
<figcaption>
Graphical model for an autoregressive Bayesian network with no conditional independence assumptions.
 </figcaption>
</figure>

<p>Such a Bayesian network that makes no conditional independence assumptions is said to obey the <em>autoregressive</em> property.
The term <em>autoregressive</em> originates from the literature on time-series models where observations from the previous time-steps are used to predict the value at the current time step. Here, we fix an ordering of the variables <script type="math/tex">x_1, x_2, \ldots, x_n</script> and the distribution for the <script type="math/tex">i</script>-th random variable depends on the values of all the preceding random variables in the chosen ordering <script type="math/tex">x_1, x_2, \ldots, x_{i-1}</script>.</p>

<p>If we allow for every conditional <script type="math/tex">% <![CDATA[
p(x_i \vert \mathbf{x}_{< i}) %]]></script> to be specified in a tabular form, then such a representation is fully general and can represent any possible distribution over <script type="math/tex">n</script> random variables. However, the space complexity for such a representation grows exponentially with <script type="math/tex">n</script>.</p>

<p>To see why, let us consider the conditional for the last dimension, given by <script type="math/tex">% <![CDATA[
p(x_n \vert \mathbf{x}_{< n}) %]]></script>. In order to fully specify this conditional, we need to specify a probability for <script type="math/tex">2^{n-1}</script> configurations of the variables <script type="math/tex">x_1, x_2, \ldots, x_{n-1}</script>. Since the probabilities should sum to 1, the total number of parameters for specifying this conditional is given by <script type="math/tex">2^{n-1} -1</script>. Hence, a tabular representation for the conditionals is impractical for learning the joint distribution factorized via chain rule.</p>

<p>In an <em>autoregressive generative model</em>, the conditionals are specified as parameterized functions with a fixed number of parameters. That is, we assume the conditional distributions <script type="math/tex">% <![CDATA[
p(x_i \vert \mathbf{x}_{< i}) %]]></script> to correspond to a Bernoulli random variable and learn a function that maps the preceding random variables <script type="math/tex">x_1, x_2, \ldots, x_{i-1}</script> to the
mean of this distribution. Hence, we have</p>
<div class="mathblock"><script type="math/tex; mode=display">
p_{\theta_i}(x_i \vert \mathbf{x}_{< i}) = \mathrm{Bern}(f_i(x_1, x_2, \ldots, x_{i-1}))
</script></div>
<p>where <script type="math/tex">\theta_i</script> denotes the set of parameters used to specify the mean
function <script type="math/tex">f_i: \{0,1\}^{i-1}\rightarrow [0,1]</script>.</p>

<p>The number of parameters of an autoregressive generative model are given by <script type="math/tex">\sum_{i=1}^n \vert \theta_i \vert</script>. As we shall see in the examples below, the number of parameters are much fewer than the tabular setting considered previously. Unlike the tabular setting, however, an autoregressive generative model cannot represent all possible distributions. Its expressiveness is limited by the fact that we are limiting the conditional distributions to correspond to a Bernoulli random variable with the mean specified via a restricted class of parameterized functions.</p>

<figure>
<img src="fvsbn.png" alt="drawing" width="200" class="center" />
<figcaption>
 A fully visible sigmoid belief network over four variables. The conditionals are denoted by \(\widehat{x}_1, \widehat{x}_2, \widehat{x}_3, \widehat{x}_4\) respectively.
 </figcaption>
</figure>
<p>In the simplest case, we can specify the function as a linear combination of the input elements followed by a sigmoid non-linearity (to restrict the output to lie between 0 and 1). This gives us the formulation of a <em>fully-visible sigmoid belief network</em> (<a href="https://papers.nips.cc/paper/1153-does-the-wake-sleep-algorithm-produce-good-density-estimators.pdf">FVSBN</a>).</p>

<div class="mathblock"><script type="math/tex; mode=display">
f_i(x_1, x_2, \ldots, x_{i-1}) =\sigma(\alpha^{(i)}_0 + \alpha^{(i)}_1 x_1 + \ldots + \alpha^{(i)}_{i-1} x_{i-1})
</script></div>

<p>where <script type="math/tex">\sigma</script> denotes the sigmoid function and <script type="math/tex">\theta_i=\{\alpha^{(i)}_0,\alpha^{(i)}_1, \ldots, \alpha^{(i)}_{i-1}\}</script> denote the parameters of the mean function. The conditional for variable <script type="math/tex">i</script> requires <script type="math/tex">i</script> parameters, and hence the total number of parameters in the model is given by <script type="math/tex">\sum_{i=1}^ni= O(n^2)</script>. Note that the number of parameters are much fewer than the exponential complexity of the tabular case.</p>

<p>A natural way to increase the expressiveness of an autoregressive generative model is to use more flexible parameterizations for the mean function, e.g. multi-layer perceptrons (MLP). For example, consider the case of a neural network with 1 hidden layer. The mean function for variable <script type="math/tex">i</script> can be expressed as</p>

<div class="mathblock"><script type="math/tex; mode=display">
\mathbf{h}_i = \sigma(A_i \mathbf{x_{< i}} + \mathbf{c}_i)\\
f_i(x_1, x_2, \ldots, x_{i-1}) =\sigma(\boldsymbol{\alpha}^{(i)}\mathbf{h}_i +b_i )
</script></div>

<p>where <script type="math/tex">\mathbf{h}_i \in \mathbb{R}^d</script> denotes the hidden layer activations for the MLP and <script type="math/tex">\theta_i = \{A_i \in \mathbb{R}^{d\times (i-1)},  \mathbf{c}_i \in \mathbb{R}^d, \boldsymbol{\alpha}^{(i)}\in \mathbb{R}^d, b_i \in \mathbb{R}\}</script>
are the set of parameters for the mean function <script type="math/tex">\mu_i(\cdot)</script>. The total number of parameters in this model is dominated by the matrices <script type="math/tex">A_i</script> and given by <script type="math/tex">O(n^2 d)</script>.</p>

<figure>
<img src="nade.png" alt="drawing" width="200" class="center" />
<figcaption>
 A neural autoregressive density estimator over four variables. The conditionals are denoted by \(\widehat{x}_1, \widehat{x}_2, \widehat{x}_3, \widehat{x}_4\) respectively. The blue connections denote the tied weights \(W[., i]\) used for computing the hidden layer activations.
 </figcaption>
</figure>

<p>The <em>Neural Autoregressive Density Estimator</em> (<a href="http://proceedings.mlr.press/v15/larochelle11a/larochelle11a.pdf">NADE</a>) provides an alternate MLP-based parameterization that is more statistically and computationally efficient than the vanilla approach. In NADE, parameters are shared across the functions used for evaluating the conditionals. In particular, the hidden layer activations are specified as</p>

<div class="mathblock"><script type="math/tex; mode=display">
\mathbf{h}_i = \sigma(W_{., < i} \mathbf{x_{< i}} + \mathbf{c})\\
f_i(x_1, x_2, \ldots, x_{i-1}) =\sigma(\boldsymbol{\alpha}^{(i)}\mathbf{h}_i +b_i )
</script></div>
<p>where <script type="math/tex">\theta=\{W\in \mathbb{R}^{d\times n}, \mathbf{c} \in \mathbb{R}^d, \{\boldsymbol{\alpha}^{(i)}\in \mathbb{R}^d\}^n_{i=1}, \{b_i \in \mathbb{R}\}^n_{i=1}\}</script>is
the full set of parameters for the mean functions <script type="math/tex">f_1(\cdot), f_2(\cdot), \ldots, f_n(\cdot)</script>. The weight matrix <script type="math/tex">W</script> and the bias vector <script type="math/tex">\mathbf{c}</script> are shared across the conditionals. Sharing parameters offers two benefits:</p>

<ol>
  <li>
    <p>The total number of parameters gets reduced from <script type="math/tex">O(n^2 d)</script> to <script type="math/tex">O(nd)</script> [readers are encouraged to check!].</p>
  </li>
  <li>
    <p>The hidden unit activations can be evaluated in <script type="math/tex">O(nd)</script> time via the following recursive strategy:</p>
    <div class="mathblock"><script type="math/tex; mode=display">
\mathbf{h}_i = \sigma(\mathbf{a}_i)\\
\mathbf{a}_{i+1} = \mathbf{a}_{i} + W[., i]x_i
</script></div>
    <p>with the base case given by <script type="math/tex">\mathbf{a}_1=\mathbf{c}</script>.</p>
  </li>
</ol>

<h3 id="extensions-to-nade">Extensions to NADE</h3>

<p>The <a href="https://arxiv.org/abs/1306.0186">RNADE</a> algorithm extends NADE to learn generative models over real-valued data. Here, the conditionals are modeled via a continuous distribution such as a equi-weighted mixture of <script type="math/tex">K</script> Gaussians. Instead of learning a mean function, we know learn the means <script type="math/tex">\mu_{i,1}, \mu_{i,2},\ldots, \mu_{i,K}</script> and variances <script type="math/tex">\Sigma_{i,1}, \Sigma_{i,2},\ldots, \Sigma_{i,K}</script> of the <script type="math/tex">K</script> Gaussians for every conditional. For statistical and computational efficiency, a single function <script type="math/tex">g_i: \mathbb{R}^{i-1}\rightarrow\mathbb{R}^{2K}</script> outputs all the means and variances of the <script type="math/tex">K</script> Gaussians for the <script type="math/tex">i</script>-th conditional distribution.</p>

<p>Notice that NADE requires specifying a single, fixed ordering of the variables. The choice of ordering can lead to different models. The <a href="https://arxiv.org/abs/1310.1757">EoNADE</a> algorithm allows training an ensemble of NADE models with different orderings.</p>

<h1 id="learning-and-inference">Learning and inference</h1>

<p>Recall that learning a generative model involves optimizing the closeness between the data and model distributions. One commonly used notion of closeness is the KL divergence between the data and the model distributions.</p>

<div class="mathblock"><script type="math/tex; mode=display">
\min_{\theta\in \mathcal{M}}d_{KL}
(p_{\mathrm{data}}, p_{\theta}) = \mathbb{E}_{\mathbf{x} \sim p_{\mathrm{data}} }\left[\log p_{\mathrm{data}}(\mathbf{x}) - \log p_{\theta}(\mathbf{x})\right]
</script></div>

<p>Before moving any further, we make two comments about the KL divergence. First, we note that the KL divergence between any two distributions is asymmetric. As we navigate through this chapter, the reader is encouraged to think what could go wrong if we decided to optimize the reverse KL divergence instead. Secondly, the KL divergences heavily penalizes any model distribution <script type="math/tex">p_\theta</script> which assigns a low probability to a datapoint that is likely to be sampled under <script type="math/tex">p_{\mathrm{data}}</script>. In the extreme case, if the density <script type="math/tex">p_\theta(\mathbf{x})</script> evaluates to zero for a datapoint sampled from <script type="math/tex">p_{\mathrm{data}}</script>, the objective evaluates to <script type="math/tex">+\infty</script>.</p>

<p>Since <script type="math/tex">p_{\mathrm{data}}</script> does not depend on <script type="math/tex">\theta</script>, we can equivalently recover the optimal parameters via maximizing likelihood estimation.</p>

<div class="mathblock"><script type="math/tex; mode=display">
\max_{\theta\in \mathcal{M}}\mathbb{E}_{\mathbf{x} \sim p_{\mathrm{data}} }\left[\log p_{\theta}(\mathbf{x})\right].
</script></div>

<p>Here, <script type="math/tex">\log p_{\theta}(\mathbf{x})</script> is referred to as the log-likelihood of the datapoint <script type="math/tex">\mathbf{x}</script> with respect to the model distribution <script type="math/tex">p_\theta</script>.</p>

<p>To approximate the expectation over the unknown <script type="math/tex">p_{\mathrm{data}}</script>, we make an assumption: points in the dataset <script type="math/tex">\mathcal{D}</script> are sampled i.i.d. from <script type="math/tex">p_{\mathrm{data}}</script>. This allows us to obtain an unbiased Monte Carlo estimate of the objective as</p>

<div class="mathblock"><script type="math/tex; mode=display">
\max_{\theta\in \mathcal{M}}\frac{1}{\vert D \vert} \sum_{\mathbf{x} \in\mathcal{D} }\log p_{\theta}(\mathbf{x}) = \mathcal{L}(\theta \vert \mathcal{D}).
 </script></div>

<p>The maximum likelihood estimation (MLE) objective has an intuitive interpretation: pick the model parameters <script type="math/tex">\theta \in \mathcal{M}</script> that maximize the log-probability of the observed datapoints in <script type="math/tex">\mathcal{D}</script>.</p>

<p>In practice, we optimize the MLE objective using mini-batch gradient ascent. The algorithm operates in iterations. At every iteration <script type="math/tex">t</script>, we sample a mini-batch <script type="math/tex">\mathcal{B}_t</script> of datapoints sampled randomly from the dataset (<script type="math/tex">% <![CDATA[
\vert \mathcal{B}_t\vert < \vert \mathcal{D} \vert %]]></script>) and compute gradients of the objective evaluated for the mini-batch. These parameters at iteration <script type="math/tex">t+1</script> are then given via the following update rule</p>
<div class="mathblock"><script type="math/tex; mode=display">
\theta^{(t+1)} = \theta^{(t)} + r_t \nabla_\theta\mathcal{L}(\theta^{(t)} \vert \mathcal{B}_t)
</script></div>

<p>where <script type="math/tex">\theta^{(t+1)}</script> and <script type="math/tex">\theta^{(t)}</script> are the parameters at iterations <script type="math/tex">t+1</script> and <script type="math/tex">t</script> respectively, and <script type="math/tex">r_t</script> is the learning rate at iteration <script type="math/tex">t</script>. Typically, we only specify the initial learning rate <script type="math/tex">r_1</script> and update the rate based on a schedule. <a href="http://cs231n.github.io/optimization-1/">Variants</a> of stochastic gradient ascent, such as RMS prop and Adam, employ modified update rules that work slightly better in practice.</p>

<p>From a practical standpoint, we must think about how to choose hyperparameters (such as the initial learning rate) and a stopping criterion for the gradient descent. For both these questions, we follow the standard practice in machine learning of monitoring the objective on a validation dataset. Consequently, we choose the hyperparameters with the best performance on the validation dataset and stop updating the parameters when the validation log-likelihoods cease to improve<sup id="fnref:1"><a href="#fn:1" class="footnote">1</a></sup>.</p>

<p>Now that we have a well-defined objective and optimization procedure, the only remaining task is to evaluate the objective in the context of an autoregressive generative model. To this end, we substitute the factorized joint distribution of an autoregressive model in the MLE objective to get</p>

<div class="mathblock"><script type="math/tex; mode=display">
\max_{\theta \in \mathcal{M}}\frac{1}{\vert D \vert} \sum_{\mathbf{x} \in\mathcal{D} }\sum_{i=1}^n\log p_{\theta_i}(x_i \vert \mathbf{x}_{< i})
</script></div>

<p>where <script type="math/tex">\theta = \{\theta_1, \theta_2, \ldots, \theta_n\}</script> now denotes the
collective set of parameters for the conditionals.</p>

<p>Inference in an autoregressive model is straightforward. For density estimation of an arbitrary point <script type="math/tex">\mathbf{x}</script>, we simply evaluate the log-conditionals <script type="math/tex">% <![CDATA[
\log p_{\theta_i}(x_i \vert \mathbf{x}_{< i}) %]]></script> for each <script type="math/tex">i</script> and add these up to obtain the log-likelihood assigned by the model to <script type="math/tex">\mathbf{x}</script>. Since we know the conditioning vector <script type="math/tex">\mathbf{x}</script>, each of the conditionals can be evaluated in parallel. Hence, density estimation is efficient on modern hardware.</p>

<p>Sampling from an autoregressive model is a sequential procedure. Here, we first sample <script type="math/tex">x_1</script>, then we sample <script type="math/tex">x_2</script> conditioned on the sampled <script type="math/tex">x_1</script>, followed by <script type="math/tex">x_3</script> conditioned on both <script type="math/tex">x_1</script> and <script type="math/tex">x_2</script> and so on until we sample <script type="math/tex">x_n</script> conditioned on the previously sampled <script type="math/tex">% <![CDATA[
\mathbf{x}_{< n} %]]></script>. For applications requiring real-time generation of high-dimensional data such as audio synthesis, the sequential sampling can be an expensive process. Later in this course, we will discuss how parallel WaveNet, an autoregressive model sidesteps this expensive sampling process.</p>

<!-- TODO: add NADE samples figure -->

<p>Finally, an autoregressive model does not directly learn unsupervised representations of the data. In the next few lectures, we will look at latent variable models (e.g., variational autoencoders) which explicitly learn latent representations of the data.</p>

<!-- 

Additional parameterizations
==============
Coming soon: MADE, Char-RNN, Pixel-CNN, Wavenet -->

<h1 id="footnotes">Footnotes</h1>

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>Given the non-convex nature of such problems, the optimization procedure can get stuck in local optima. Hence, early stopping will generally not be optimal but is a very practical strategy. <a href="#fnref:1" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>



    </article>
    <span class="print-footer">Autoregressive Models - Aditya Grover</span>
    <footer>
  <hr class="slender">
  <!-- <ul class="footer&#45;links"> -->
  <!--   <li><a href="mailto:hate@spam.net"><span class="icon&#45;mail"></span></a></li>     -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.twitter.com/twitter_handle"><span class="icon-twitter"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//plus.google.com/+googlePlusName"><span class="icon-googleplus"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//github.com/GithubHandle"><span class="icon-github"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="//www.flickr.com/photos/FlickrUserID"><span class="icon-flickr"></span></a> -->
  <!--     </li> -->
  <!--    -->
  <!--     <li> -->
  <!--       <a href="/feed"><span class="icon-feed"></span></a> -->
  <!--     </li> -->
  <!--      -->
  <!-- </ul> -->
<div class="credits">
<!-- <span>&#38;copy; 2018 <!&#45;&#45; &#38;#38;nbsp;&#38;#38;nbsp;ADITYA GROVER &#45;&#45;></span></br> <br> -->
<span>Site created with <a href="//jekyllrb.com">Jekyll</a> using the <a href="//github.com/clayh53/tufte-jekyll">Tufte theme</a>. &copy; 2018</span> 
</div>  
</footer>

  </body>
</html>
